
************************************** Experiements **************************************

################################################
########### Random Forest Classifier ###########
################################################

EMBEDDING: 80-mel

data -- TIMIT/TRAIN/DR1/*
train:test -- 7:3 of the data

Hyperparameters:
n_estimators = 200
max_depth = 30
random_state = 42

rf = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42)

SCORE: 0.36203703703703705

###############################
########### XGBoost ###########
###############################

EMBEDDING: 80-mel

data -- TIMIT/TRAIN/*
train:test -- 7:3 of the data

Hyperparameters:
params = {"max_depth": 20, 
          "eta": 0.3, 
          "num_class": 61, 
          "gamma": 1, 
          "lambda": 10, 
          "alpha": 10}
params["objective"] = "multi:softmax"
params["eval_metric"] = "merror"
params['nthread'] = 4
num_round = 30

SCORE: 0.3975715361445783

#############################################
########### PCA Cosine similarity ###########
#############################################

EMBEDDING: 80-mel

data -- TIMIT/TRAIN/*
train:test -- 7:3 of the data

Hyperparameters:
20 PC features - 
SCORE: 0.22060185185185185

full 80 features - 
SCORE: 0.22407407407407406

###############################
########### FC - NN ###########
###############################

EMBEDDING: 80-mel

train_data -- TIMIT/TRAIN/*
test_data -- TIMIT/TEST/*

Network Architecture:
class TimitMelClassifier(nn.Module):
    def __init__(self):
        super(TimitMelClassifier, self).__init__()
        embedding_dim = 80
        output_dim = 61
        self.net = nn.Sequential(
            nn.Linear(embedding_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim)
        )
    def forward(self, inp):
        return self.net(inp)
        
Hyperparameters:
batch_size = 128
epochs = 20
eta = 1e-4
objective = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=eta)

SCORE: 0.3561549855772979

epochs = 100
SCORE: 0.44212988227956657

###############################
########### CNN - 1 ###########
###############################

EMBEDDING: 80-mel

train_data -- TIMIT/TRAIN/*
test_data -- TIMIT/TEST/*

Network Architecture:
class TimitMelClassifier(nn.Module):
    def __init__(self):
        super(TimitMelClassifier, self).__init__()
        embedding_dim = 80
        output_dim = 61
        self.conv1 = nn.Conv1d(1, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm1d(64)
        self.conv2 = nn.Conv1d(64, 64, 5, padding=2)
        self.bn2 = nn.BatchNorm1d(64)
        self.conv3 = nn.Conv1d(64, 64, 7, padding=3)
        self.bn3 = nn.BatchNorm1d(64)
        self.conv4 = nn.Conv1d(64, 64, 9, padding=4)
        self.bn4 = nn.BatchNorm1d(64)
        self.conv5 = nn.Conv1d(64, 64, 11, padding=5)
        self.bn5 = nn.BatchNorm1d(64)
        self.conv6 = nn.Conv1d(64, 64, 13, padding=6)
        self.bn6 = nn.BatchNorm1d(64)
        self.conv7 = nn.Conv1d(64, 64, 15, padding=7)
        self.bn7 = nn.BatchNorm1d(64)
        self.conv8 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn8 = nn.BatchNorm1d(64)
        self.conv9 = nn.Conv1d(64, 64, 2, stride=2)
        self.bn9 = nn.BatchNorm1d(64)
        self.conv10 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn10 = nn.BatchNorm1d(64)
        self.conv11 = nn.Conv1d(64, 64, 2, stride=2)
        self.bn11 = nn.BatchNorm1d(64)
        self.conv12 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn12 = nn.BatchNorm1d(64)
        self.conv13 = nn.Conv1d(64, 64, 2, stride=2)
        self.bn13 = nn.BatchNorm1d(64)
        self.conv14 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn14 = nn.BatchNorm1d(64)
        self.conv15 = nn.Conv1d(64, 64, 10)
        
        self.fc1 = nn.Linear(64, 64)
        self.fc2 = nn.Linear(64, output_dim)
        
    def forward(self, inp):
        y = self.bn1(F.relu(self.conv1(inp)))
        y = y + self.bn2(F.relu(self.conv2(y)))
        y = y + self.bn3(F.relu(self.conv3(y)))
        y = y + self.bn4(F.relu(self.conv4(y)))
        y = y + self.bn5(F.relu(self.conv5(y)))
        y = y + self.bn6(F.relu(self.conv6(y)))
        y = y + self.bn7(F.relu(self.conv7(y)))
        y = y + self.bn8(F.relu(self.conv8(y)))
        y = self.bn9(F.relu(self.conv9(y)))
        y = y + self.bn10(F.relu(self.conv10(y)))
        y = self.bn11(F.relu(self.conv11(y)))
        y = y + self.bn12(F.relu(self.conv12(y)))
        y = self.bn13(F.relu(self.conv13(y)))
        y = y + self.bn14(F.relu(self.conv14(y)))
        y = F.relu(self.conv15(y))
        y = y.squeeze(2)
        y = F.relu(self.fc1(y))
        y = F.relu(self.fc2(y))
        
        return y
        
Hyperparameters:
batch_size = 128
epochs = 20
eta = 1e-4
objective = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=eta)

SCORE: 0.39678802525921886

###############################
########### CNN - 1 ###########
###############################

EMBEDDING: 80-mel

train_data -- TIMIT/TRAIN/*
test_data -- TIMIT/TEST/*

Network Architecture:
class TimitMelClassifier(nn.Module):
    def __init__(self):
        super(TimitMelClassifier, self).__init__()
        embedding_dim = 80
        output_dim = 61
        self.conv1 = nn.Conv1d(1, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm1d(64)
        self.conv2 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm1d(64)
        self.conv3 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn3 = nn.BatchNorm1d(64)
        self.conv4 = nn.Conv1d(64, 64, 3, padding=1)
        self.bn4 = nn.BatchNorm1d(64)
        self.conv5 = nn.Conv1d(64, 32, 3, padding=1)
        self.bn5 = nn.BatchNorm1d(32)
        self.conv6 = nn.Conv1d(32, 16, 3, padding=1)
        self.bn6 = nn.BatchNorm1d(16)
        self.conv7 = nn.Conv1d(16, 8, 3, padding=1)
        self.bn7 = nn.BatchNorm1d(8)
        self.conv8 = nn.Conv1d(8, 4, 3, padding=1)
        self.bn8 = nn.BatchNorm1d(4)
        self.conv9 = nn.Conv1d(4, 2, 3, padding=1)
        self.bn9 = nn.BatchNorm1d(2)
        self.conv10 = nn.Conv1d(2, 1, 3, padding=1)
        
        self.fc1 = nn.Linear(embedding_dim, embedding_dim)
        self.fc2 = nn.Linear(embedding_dim, output_dim)
        
    def forward(self, inp):
        y = self.bn1(F.relu(self.conv1(inp)))
        y = self.bn2(F.relu(self.conv2(y)))
        y = self.bn3(F.relu(self.conv3(y)))
        y = self.bn4(F.relu(self.conv4(y)))
        y = self.bn5(F.relu(self.conv5(y)))
        y = self.bn6(F.relu(self.conv6(y)))
        y = self.bn7(F.relu(self.conv7(y)))
        y = self.bn8(F.relu(self.conv8(y)))
        y = self.bn9(F.relu(self.conv9(y)))
        y = F.relu(self.conv10(y))
        y = y.squeeze(1)
        y = F.relu(self.fc1(y))
        y = F.relu(self.fc2(y))
        
        return y

Hyperparameters:
batch_size = 128
epochs = 20
eta = 1e-4
objective = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=eta)

SCORE: 0.3887892726280502




