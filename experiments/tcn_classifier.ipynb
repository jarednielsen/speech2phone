{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Networks\n",
    "See https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-3-7f6633fcc7c7 and https://github.com/locuslab/TCN/blob/master/TCN/tcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from speech2phone.preprocessing.TIMIT.phones import get_data, get_phones, phones\n",
    "from speech2phone.experiments.tcn import TemporalConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data, y):\n",
    "    \"\"\"Resample audio to 800 points.\"\"\"\n",
    "    return signal.resample(data, 800), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/resample/500 set from cache... done.\n"
     ]
    }
   ],
   "source": [
    "audio, labels = get_data(preprocessor=resample, batch_preprocess=False, TIMIT_root='../TIMIT/TIMIT', padding=500)\n",
    "phonemes = get_phones(labels)\n",
    "n_phones = len(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([132810, 800])\n",
      "torch.Size([132810])\n"
     ]
    }
   ],
   "source": [
    "audio_tensor = torch.Tensor(audio)\n",
    "labels_tensor = torch.Tensor(labels)\n",
    "print(audio_tensor.shape)\n",
    "print(labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TensorDataset(audio_tensor, labels_tensor) # Dataset requires same batch dimension\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per Epoch: 934\n",
      "[1,    20] loss: 5.149 train acc 0.023 test acc: 0.026\n",
      "[1,    40] loss: 4.322 train acc 0.016 test acc: 0.023\n",
      "[1,    60] loss: 4.163 train acc 0.031 test acc: 0.027\n",
      "[1,    80] loss: 4.132 train acc 0.047 test acc: 0.020\n",
      "[1,   100] loss: 4.117 train acc 0.031 test acc: 0.017\n",
      "[1,   120] loss: 4.113 train acc 0.023 test acc: 0.017\n",
      "[1,   140] loss: 4.109 train acc 0.031 test acc: 0.022\n",
      "[1,   160] loss: 4.114 train acc 0.008 test acc: 0.021\n",
      "[1,   180] loss: 4.108 train acc 0.047 test acc: 0.018\n",
      "[1,   200] loss: 4.103 train acc 0.023 test acc: 0.019\n",
      "[1,   220] loss: 4.114 train acc 0.023 test acc: 0.014\n",
      "[1,   240] loss: 4.110 train acc 0.008 test acc: 0.012\n",
      "[1,   260] loss: 4.109 train acc 0.008 test acc: 0.015\n",
      "[1,   280] loss: 4.114 train acc 0.016 test acc: 0.013\n",
      "[1,   300] loss: 4.111 train acc 0.023 test acc: 0.011\n",
      "[1,   320] loss: 4.107 train acc 0.031 test acc: 0.015\n",
      "[1,   340] loss: 4.098 train acc 0.031 test acc: 0.021\n",
      "[1,   360] loss: 4.105 train acc 0.023 test acc: 0.021\n",
      "[1,   380] loss: 4.105 train acc 0.016 test acc: 0.012\n",
      "[1,   400] loss: 4.112 train acc 0.031 test acc: 0.018\n",
      "[1,   420] loss: 4.112 train acc 0.016 test acc: 0.012\n",
      "[1,   440] loss: 4.105 train acc 0.016 test acc: 0.021\n",
      "[1,   460] loss: 4.103 train acc 0.031 test acc: 0.023\n",
      "[1,   480] loss: 4.102 train acc 0.008 test acc: 0.020\n",
      "[1,   500] loss: 4.102 train acc 0.047 test acc: 0.021\n",
      "[1,   520] loss: 4.096 train acc 0.047 test acc: 0.027\n",
      "[1,   540] loss: 4.090 train acc 0.031 test acc: 0.021\n",
      "[1,   560] loss: 4.102 train acc 0.016 test acc: 0.022\n",
      "[1,   580] loss: 4.108 train acc 0.039 test acc: 0.018\n",
      "[1,   600] loss: 4.105 train acc 0.023 test acc: 0.022\n",
      "[1,   620] loss: 4.099 train acc 0.047 test acc: 0.032\n",
      "[1,   640] loss: 4.102 train acc 0.016 test acc: 0.022\n",
      "[1,   660] loss: 4.090 train acc 0.078 test acc: 0.030\n",
      "[1,   680] loss: 4.090 train acc 0.039 test acc: 0.034\n",
      "[1,   700] loss: 4.092 train acc 0.039 test acc: 0.037\n",
      "[1,   720] loss: 4.094 train acc 0.039 test acc: 0.030\n",
      "[1,   740] loss: 4.086 train acc 0.047 test acc: 0.038\n",
      "[1,   760] loss: 4.093 train acc 0.031 test acc: 0.030\n",
      "[1,   780] loss: 4.086 train acc 0.070 test acc: 0.039\n",
      "[1,   800] loss: 4.083 train acc 0.023 test acc: 0.043\n",
      "[1,   820] loss: 4.081 train acc 0.078 test acc: 0.040\n",
      "[1,   840] loss: 4.079 train acc 0.078 test acc: 0.047\n",
      "[1,   860] loss: 4.052 train acc 0.055 test acc: 0.057\n",
      "[1,   880] loss: 4.044 train acc 0.070 test acc: 0.047\n",
      "[1,   900] loss: 4.055 train acc 0.062 test acc: 0.051\n",
      "[1,   920] loss: 4.051 train acc 0.086 test acc: 0.053\n",
      "[2,    20] loss: 3.990 train acc 0.070 test acc: 0.057\n",
      "[2,    40] loss: 4.020 train acc 0.047 test acc: 0.059\n",
      "[2,    60] loss: 3.994 train acc 0.094 test acc: 0.062\n",
      "[2,    80] loss: 3.993 train acc 0.070 test acc: 0.053\n",
      "[2,   100] loss: 4.009 train acc 0.047 test acc: 0.065\n",
      "[2,   120] loss: 3.975 train acc 0.070 test acc: 0.062\n",
      "[2,   140] loss: 3.950 train acc 0.070 test acc: 0.064\n",
      "[2,   160] loss: 3.967 train acc 0.055 test acc: 0.069\n",
      "[2,   180] loss: 3.938 train acc 0.078 test acc: 0.069\n",
      "[2,   200] loss: 3.932 train acc 0.125 test acc: 0.079\n",
      "[2,   220] loss: 3.894 train acc 0.070 test acc: 0.082\n",
      "[2,   240] loss: 3.900 train acc 0.094 test acc: 0.085\n",
      "[2,   260] loss: 3.837 train acc 0.047 test acc: 0.092\n",
      "[2,   280] loss: 3.805 train acc 0.086 test acc: 0.089\n",
      "[2,   300] loss: 3.865 train acc 0.094 test acc: 0.091\n",
      "[2,   320] loss: 3.793 train acc 0.117 test acc: 0.100\n",
      "[2,   340] loss: 3.789 train acc 0.094 test acc: 0.107\n",
      "[2,   360] loss: 3.742 train acc 0.148 test acc: 0.101\n",
      "[2,   380] loss: 3.692 train acc 0.117 test acc: 0.108\n",
      "[2,   400] loss: 3.695 train acc 0.180 test acc: 0.113\n",
      "[2,   420] loss: 3.709 train acc 0.148 test acc: 0.118\n",
      "[2,   440] loss: 3.662 train acc 0.172 test acc: 0.104\n",
      "[2,   460] loss: 3.623 train acc 0.070 test acc: 0.102\n",
      "[2,   480] loss: 3.631 train acc 0.102 test acc: 0.119\n",
      "[2,   500] loss: 3.599 train acc 0.172 test acc: 0.134\n",
      "[2,   520] loss: 3.561 train acc 0.195 test acc: 0.128\n",
      "[2,   540] loss: 3.511 train acc 0.109 test acc: 0.125\n",
      "[2,   560] loss: 3.583 train acc 0.148 test acc: 0.142\n",
      "[2,   580] loss: 3.511 train acc 0.195 test acc: 0.142\n",
      "[2,   600] loss: 3.544 train acc 0.195 test acc: 0.148\n",
      "[2,   620] loss: 3.449 train acc 0.203 test acc: 0.161\n",
      "[2,   640] loss: 3.416 train acc 0.164 test acc: 0.153\n",
      "[2,   660] loss: 3.463 train acc 0.125 test acc: 0.169\n",
      "[2,   680] loss: 3.440 train acc 0.156 test acc: 0.153\n",
      "[2,   700] loss: 3.418 train acc 0.211 test acc: 0.150\n",
      "[2,   720] loss: 3.366 train acc 0.141 test acc: 0.155\n",
      "[2,   740] loss: 3.353 train acc 0.195 test acc: 0.171\n",
      "[2,   760] loss: 3.326 train acc 0.211 test acc: 0.166\n",
      "[2,   780] loss: 3.341 train acc 0.227 test acc: 0.152\n",
      "[2,   800] loss: 3.310 train acc 0.164 test acc: 0.147\n",
      "[2,   820] loss: 3.356 train acc 0.203 test acc: 0.166\n",
      "[2,   840] loss: 3.317 train acc 0.211 test acc: 0.148\n",
      "[2,   860] loss: 3.279 train acc 0.211 test acc: 0.176\n",
      "[2,   880] loss: 3.225 train acc 0.188 test acc: 0.174\n",
      "[2,   900] loss: 3.256 train acc 0.234 test acc: 0.168\n",
      "[2,   920] loss: 3.268 train acc 0.164 test acc: 0.158\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = TemporalConvNet(num_inputs=800, num_channels=[400, 200, 61])\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "n_epochs = 2\n",
    "n_print_every = 20\n",
    "\n",
    "print(\"Batches per Epoch: {}\".format(len(train_loader)))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, y_truth = data\n",
    "        inputs = inputs.unsqueeze(-1)\n",
    "        y_truth = y_truth.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(2)\n",
    "#         print(\"inputs: {}, outputs: {}, labels: {}\".format(inputs.shape, outputs.shape, y_truth.shape))\n",
    "        loss = criterion(outputs, y_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(outputs, dim=1)\n",
    "#         print(y_pred)\n",
    "#         print(y_truth)\n",
    "        train_acc = (y_pred == y_truth).float().mean()\n",
    "#         print(\"acc: {}\".format(acc))\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_print_every == n_print_every - 1:    # print every 2000 mini-batches\n",
    "            inputs, y_truth = next(iter(test_loader))\n",
    "            inputs = inputs.unsqueeze(-1)\n",
    "            y_truth = y_truth.long()\n",
    "            y_pred = torch.argmax(model(inputs).squeeze(2), dim=1)\n",
    "            test_acc = (y_pred == y_truth).float().mean()\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f train acc %.3f test acc: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / n_print_every, train_acc, test_acc))\n",
    "            running_loss = 0.0\n",
    "                            \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.6689e+02, -9.7737e+01, -5.7501e+01,  ...,  4.4316e+02,\n",
       "           9.6222e+02,  7.9342e+02],\n",
       "         [-9.9992e+00, -3.8094e+01,  1.0531e+01,  ..., -1.5922e+00,\n",
       "          -1.1099e+01,  3.5163e-01],\n",
       "         [-5.7790e+01, -1.3027e+02, -1.0136e+02,  ...,  3.3090e+00,\n",
       "           6.4288e+01,  1.1337e+02],\n",
       "         ...,\n",
       "         [ 8.9595e+01,  2.7653e+01, -2.3872e+01,  ..., -2.8324e+02,\n",
       "          -6.2566e+01,  2.0179e+02],\n",
       "         [-1.0767e+02, -2.6406e+01, -4.3547e+01,  ..., -1.5874e+02,\n",
       "          -2.6272e+02, -8.6479e+01],\n",
       "         [ 1.5602e+01, -3.2628e+00, -2.1959e+01,  ...,  1.0605e+01,\n",
       "           2.9967e+01,  2.8923e+01]]),\n",
       " tensor([37., 19., 57.,  ..., 58., 31., 23.])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
